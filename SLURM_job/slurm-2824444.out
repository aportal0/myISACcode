r5-r6i1p1
cp: cannot stat '/mnt/naszappa/CRCM5-LE/CanESM2_driven/pr/daily/pr_daysum_historical_195501-200512_kct.nc': No such file or directory
Warning (cdf_check_variables): Unsupported data type (char/string), skipped variable rotated_pole!
Warning (cdfInqContents): No data arrays found!
cdo    remapbil: Open failed on >/home/portal/work_big/CRCM5-LE/pr/pr_daysum_historical_195501-200512_kct.nc<
                 Unsupported file structure
cp: cannot stat '/mnt/naszappa/CRCM5-LE/CanESM2_driven/pr/daily/pr_daysum_rcp85_200601-209812_kct.nc': No such file or directory
nco_err_exit(): ERROR Short NCO-generated message (usually name of function that triggered error): nco__open()
nco_err_exit(): ERROR Error code is -101. Translation into English with nc_strerror(-101) is "NetCDF: HDF error"
ERROR: nco__open() unable to open file "/home/portal/work_big/CRCM5-LE/pr/pr_daysum_rcp85_200601-209812_kct.nc.pid149801.ncks.tmp"
ERROR NC_EHDFERR Error at HDF5 layer
HINT: NC_EHDFERR errors indicate that the HDF5-backend to netCDF is unable to perform the requested task. NCO can receive this devilishly inscrutable error for a variety of possible reasons including: 1) The run-time dynamic linker attempts to resolve calls from the netCDF library to the HDF library with an HDF5 libhdf5.a that is incompatible with the version used to build NCO and netCDF. 2) The file system does not allow the HDF5 flock() function, as of HDF5 1.10.x, to enable multiple processes to open the same file for reading, a feature known as SWMR (Single Write Multiple Read). The fix is to disable the HDF5 flock() by setting an environment variable thusly: "export HDF5_USE_FILE_LOCKING=FALSE". 3) An incorrect netCDF4 library implementation of a procedure (e.g., nc_rename_var()) in terms of HDF function calls (e.g., HDF5Lmove()) manifests an error or inconsistent state within the HDF5 layer. This often occurs during renaming operations (https://github.com/Unidata/netcdf-c/issues/597). 4) Attempting to compress or decompress a netCDF4 dataset with a non-standard (i.e., non-DEFLATE) filter when the requisite shared library to encode/decode that compression filter is not present in either the default location (/usr/local/hdf5/lib/plugin) or in the user-configurable location referred to by the HDF5_PLUGIN_PATH environment variable. One can determine if missing plugin libraries are the culprit by dumping the hidden attributes of the dataset with, e.g., ncks --hdn -m in.nc or ncdump -s -h in.nc. Any variables with (hidden) "_Filter" attributes require the corresponding shared libraries to be located in HDF5_PLUGIN_PATH. Some HDF5 implementations (at least MacOSX with MacPorts as of 20200907) may also require explicitly setting the plugin path in the environment, even for the default location! To test this, re-try your NCO command after doing this: "export HDF5_PLUGIN_PATH=/usr/local/hdf5/lib/plugin". 5) Bad vibes.
nco_err_exit(): ERROR NCO will now exit with system call exit(EXIT_FAILURE)
cdo    remapbil: Open failed on >/home/portal/work_big/CRCM5-LE/pr/pr_daysum_rcp85_200601-209812_kct.nc<
                 Unknown Error
