{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'msl'\n",
    "varstr = 'mslp'\n",
    "n_window = 31\n",
    "data_dir = '/work_big/users/portal/ERA5/'+varstr+'/'\n",
    "year_range = [2004, 2023]   # for reference climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_2004.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_2005.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_2006.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_2007.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_2008.nc']\n",
      "['/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_1985.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_1986.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_1987.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_1988.nc', '/work_big/users/portal/ERA5/mslp/ERA5_mslp_NH_daily_1989.nc']\n"
     ]
    }
   ],
   "source": [
    "# Define the file pattern\n",
    "file_pattern = data_dir + \"ERA5_\"+varstr+\"_NH_daily_????.nc\"\n",
    "# Get all file paths matching the pattern\n",
    "all_files = glob.glob(file_pattern)\n",
    "# Select and sort files\n",
    "selected_files = []\n",
    "for year in range(year_range[0], year_range[1]+1):\n",
    "    selected_files += [file for file in all_files if str(year) in file]\n",
    "selected_files = sorted(selected_files)\n",
    "print(selected_files[:5])\n",
    "print(sorted(all_files)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and compute climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Upload data and compute the daily climatology\u001b[39;00m\n\u001b[1;32m      7\u001b[0m data_daily \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(\n\u001b[1;32m      8\u001b[0m     selected_files, \\\n\u001b[1;32m      9\u001b[0m     use_cftime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \\\n\u001b[1;32m     10\u001b[0m     combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     11\u001b[0m     chunks\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m}, \\\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m clim_daily \u001b[38;5;241m=\u001b[39m \u001b[43mdaily_clim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_daily\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save the daily climatology\u001b[39;00m\n\u001b[1;32m     16\u001b[0m clim_daily\u001b[38;5;241m.\u001b[39mto_netcdf(data_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclimatology/ERA5_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mvarstr\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_NH_daily_clim_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(year_range[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(year_range[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/site-packages/xarray/core/dataarray.py:1204\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;124;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/site-packages/xarray/core/dataarray.py:1172\u001b[0m, in \u001b[0;36mDataArray.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;124;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1172\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(ds)\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable \u001b[38;5;241m=\u001b[39m new\u001b[38;5;241m.\u001b[39m_variable\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/site-packages/xarray/core/dataset.py:873\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    872\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/site-packages/dask/base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/queue.py:202\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "File \u001b[0;32m~/anaconda3/envs/geo_env/lib/python3.13/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define postprocessing function\n",
    "def daily_clim(ds, var_name=varname):\n",
    "    ds_clim = ds.groupby(\"time.dayofyear\").mean(\"time\")[var_name]\n",
    "    return ds_clim\n",
    "\n",
    "# Upload data and compute the daily climatology\n",
    "data_daily = xr.open_mfdataset(\n",
    "    selected_files, \\\n",
    "    use_cftime=True, \\\n",
    "    combine='by_coords', \\\n",
    "    chunks={'time': -1, 'lon': -1, 'lat': 10}, \\\n",
    "    )\n",
    "clim_daily = daily_clim(data_daily).compute()\n",
    "\n",
    "# Save the daily climatology\n",
    "clim_daily.to_netcdf(data_dir + 'climatology/ERA5_'+varstr+'_NH_daily_clim_'+str(year_range[0])+'-'+str(year_range[1])+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend and smooth the daily climatology with a n_window running mean\n",
    "n_days = np.floor(n_window / 2).astype(int)\n",
    "clim_extended = xr.concat(\n",
    "    [clim_daily[-n_days:], clim_daily, clim_daily[:n_days]],\n",
    "    dim=\"dayofyear\"\n",
    ")\n",
    "new_dayofyear = np.arange(-n_days + 1, 365 + n_days + 1)\n",
    "clim_extended = clim_extended.assign_coords(dayofyear=new_dayofyear)\n",
    "clim_smooth = clim_extended.rolling(dayofyear=n_window, center=True).mean()\n",
    "clim_smooth = clim_smooth.sel(dayofyear=slice(1, 365))\n",
    "\n",
    "# Save the smoothed climatology\n",
    "clim_smooth.to_netcdf(data_dir + 'climatology/ERA5_'+varstr+'_NH_daily_clim_'+str(year_range[0])+'-'+str(year_range[1])+'_sm'+str(n_window)+'d.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute anomalies from climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  ERA5_mslp_NH_daily_1985  is saved\n",
      "File  ERA5_mslp_NH_daily_1986  is saved\n",
      "File  ERA5_mslp_NH_daily_1987  is saved\n",
      "File  ERA5_mslp_NH_daily_1988  is saved\n",
      "File  ERA5_mslp_NH_daily_1989  is saved\n",
      "File  ERA5_mslp_NH_daily_1990  is saved\n",
      "File  ERA5_mslp_NH_daily_1991  is saved\n",
      "File  ERA5_mslp_NH_daily_1992  is saved\n",
      "File  ERA5_mslp_NH_daily_1993  is saved\n",
      "File  ERA5_mslp_NH_daily_1995  is saved\n",
      "File  ERA5_mslp_NH_daily_1996  is saved\n",
      "File  ERA5_mslp_NH_daily_1997  is saved\n",
      "File  ERA5_mslp_NH_daily_1998  is saved\n",
      "File  ERA5_mslp_NH_daily_1999  is saved\n",
      "File  ERA5_mslp_NH_daily_2000  is saved\n",
      "File  ERA5_mslp_NH_daily_2001  is saved\n",
      "File  ERA5_mslp_NH_daily_2002  is saved\n",
      "File  ERA5_mslp_NH_daily_2003  is saved\n",
      "File  ERA5_mslp_NH_daily_2004  is saved\n",
      "File  ERA5_mslp_NH_daily_2005  is saved\n",
      "File  ERA5_mslp_NH_daily_2006  is saved\n",
      "File  ERA5_mslp_NH_daily_2007  is saved\n",
      "File  ERA5_mslp_NH_daily_2008  is saved\n",
      "File  ERA5_mslp_NH_daily_2009  is saved\n",
      "File  ERA5_mslp_NH_daily_2010  is saved\n",
      "File  ERA5_mslp_NH_daily_2011  is saved\n",
      "File  ERA5_mslp_NH_daily_2012  is saved\n",
      "File  ERA5_mslp_NH_daily_2013  is saved\n",
      "File  ERA5_mslp_NH_daily_2014  is saved\n",
      "File  ERA5_mslp_NH_daily_2015  is saved\n",
      "File  ERA5_mslp_NH_daily_2016  is saved\n",
      "File  ERA5_mslp_NH_daily_2017  is saved\n",
      "File  ERA5_mslp_NH_daily_2018  is saved\n",
      "File  ERA5_mslp_NH_daily_2019  is saved\n",
      "File  ERA5_mslp_NH_daily_2020  is saved\n",
      "File  ERA5_mslp_NH_daily_2021  is saved\n",
      "File  ERA5_mslp_NH_daily_2022  is saved\n",
      "File  ERA5_mslp_NH_daily_2023  is saved\n"
     ]
    }
   ],
   "source": [
    "for file in sorted(all_files):\n",
    "    data = xr.open_dataset(file)\n",
    "    clim = xr.open_dataset(data_dir + 'climatology/ERA5_'+varstr+'_NH_daily_clim_'+str(year_range[0])+'-'+str(year_range[1])+'_sm'+str(n_window)+'d.nc')\n",
    "    clim = clim.sel(dayofyear=data['time'].dt.dayofyear).drop_vars(\"dayofyear\")\n",
    "    anom = data - clim\n",
    "    anom.to_netcdf(data_dir + file.split('/')[-1].split('.')[0] + '_anom.nc')\n",
    "    print('File ', file.split('/')[-1].split('.')[0] + '_anom.nc is saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
