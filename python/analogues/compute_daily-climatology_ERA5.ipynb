{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'msl'\n",
    "varstr = 'mslp'\n",
    "n_window = 31\n",
    "data_dir = '/mnt/naszappa/portal/ERA5/'+varstr+'/'\n",
    "year_range = [2004, 2023]   # for reference climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_2004.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_2005.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_2006.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_2007.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_2008.nc']\n",
      "['/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_1985.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_1986.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_1987.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_1988.nc', '/mnt/naszappa/portal/ERA5/mslp/ERA5_mslp_NH_daily_1989.nc']\n"
     ]
    }
   ],
   "source": [
    "# Define the file pattern\n",
    "file_pattern = data_dir + \"ERA5_\"+varstr+\"_NH_daily_????.nc\"\n",
    "# Get all file paths matching the pattern\n",
    "all_files = glob.glob(file_pattern)\n",
    "# Select and sort files\n",
    "selected_files = []\n",
    "for year in range(year_range[0], year_range[1]+1):\n",
    "    selected_files += [file for file in all_files if str(year) in file]\n",
    "selected_files = sorted(selected_files)\n",
    "print(selected_files[:5])\n",
    "print(sorted(all_files)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and compute climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n",
      "/tmp/ipykernel_1525082/74372554.py:7: DeprecationWarning: Usage of 'use_cftime' as a kwarg is deprecated. Please pass a 'CFDatetimeCoder' instance initialized with 'use_cftime' to the 'decode_times' kwarg instead.\n",
      "Example usage:\n",
      "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
      "    ds = xr.open_dataset(decode_times=time_coder)\n",
      "\n",
      "  data_daily = xr.open_mfdataset(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Upload data and compute the daily climatology\u001b[39;00m\n\u001b[32m      7\u001b[39m data_daily = xr.open_mfdataset(\n\u001b[32m      8\u001b[39m     selected_files, \\\n\u001b[32m      9\u001b[39m     use_cftime=\u001b[38;5;28;01mTrue\u001b[39;00m, \\\n\u001b[32m     10\u001b[39m     combine=\u001b[33m'\u001b[39m\u001b[33mby_coords\u001b[39m\u001b[33m'\u001b[39m, \\\n\u001b[32m     11\u001b[39m     chunks={\u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m: -\u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m10\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m'\u001b[39m: -\u001b[32m1\u001b[39m}, \\\n\u001b[32m     12\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m clim_daily = \u001b[43mdaily_clim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_daily\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Save the daily climatology\u001b[39;00m\n\u001b[32m     16\u001b[39m clim_daily.to_netcdf(data_dir + \u001b[33m'\u001b[39m\u001b[33mclimatology/ERA5_\u001b[39m\u001b[33m'\u001b[39m+varstr+\u001b[33m'\u001b[39m\u001b[33m_NH_daily_clim_\u001b[39m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(year_range[\u001b[32m0\u001b[39m])+\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m+\u001b[38;5;28mstr\u001b[39m(year_range[\u001b[32m1\u001b[39m])+\u001b[33m'\u001b[39m\u001b[33m.nc\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/site-packages/xarray/core/dataarray.py:1189\u001b[39m, in \u001b[36mDataArray.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[33;03mremote source into memory and return a new array.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m \u001b[33;03mdask.compute\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1188\u001b[39m new = \u001b[38;5;28mself\u001b[39m.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/site-packages/xarray/core/dataarray.py:1157\u001b[39m, in \u001b[36mDataArray.load\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs) -> Self:\n\u001b[32m   1138\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[33;03m    remote source into memory and return this array.\u001b[39;00m\n\u001b[32m   1140\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1155\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m   1156\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1157\u001b[39m     ds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1158\u001b[39m     new = \u001b[38;5;28mself\u001b[39m._from_temp_dataset(ds)\n\u001b[32m   1159\u001b[39m     \u001b[38;5;28mself\u001b[39m._variable = new._variable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/site-packages/xarray/core/dataset.py:542\u001b[39m, in \u001b[36mDataset.load\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    539\u001b[39m chunkmanager = get_chunked_array_type(*lazy_data.values())\n\u001b[32m    541\u001b[39m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np.ndarray[Any, Any], ...] = \u001b[43mchunkmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mlazy_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    547\u001b[39m     \u001b[38;5;28mself\u001b[39m.variables[k].data = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/site-packages/xarray/namedarray/daskmanager.py:85\u001b[39m, in \u001b[36mDaskManager.compute\u001b[39m\u001b[34m(self, *data, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mself\u001b[39m, *data: Any, **kwargs: Any\n\u001b[32m     82\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray[Any, _DType_co], ...]:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdask\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/site-packages/dask/base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/queue.py:171\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must be a non-negative number\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/geo_env_xesmf/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define postprocessing function\n",
    "def daily_clim(ds, var_name=varname):\n",
    "    ds_clim = ds.groupby(\"time.dayofyear\").mean(\"time\")[var_name]\n",
    "    return ds_clim\n",
    "\n",
    "# Upload data and compute the daily climatology\n",
    "data_daily = xr.open_mfdataset(\n",
    "    selected_files, \\\n",
    "    use_cftime=True, \\\n",
    "    combine='by_coords', \\\n",
    "    chunks={'longitude': -1, 'lat': 10,'time': -1}, \\\n",
    "    )\n",
    "clim_daily = daily_clim(data_daily).compute()\n",
    "\n",
    "# Save the daily climatology\n",
    "clim_daily.to_netcdf(data_dir + 'climatology/ERA5_'+varstr+'_NH_daily_clim_'+str(year_range[0])+'-'+str(year_range[1])+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend and smooth the daily climatology with a n_window running mean\n",
    "n_days = np.floor(n_window / 2).astype(int)\n",
    "clim_extended = xr.concat(\n",
    "    [clim_daily[-n_days:], clim_daily, clim_daily[:n_days]],\n",
    "    dim=\"dayofyear\"\n",
    ")\n",
    "new_dayofyear = np.arange(-n_days + 1, 365 + n_days + 1)\n",
    "clim_extended = clim_extended.assign_coords(dayofyear=new_dayofyear)\n",
    "clim_smooth = clim_extended.rolling(dayofyear=n_window, center=True).mean()\n",
    "clim_smooth = clim_smooth.sel(dayofyear=slice(1, 365))\n",
    "\n",
    "# Save the smoothed climatology\n",
    "clim_smooth.to_netcdf(data_dir + 'climatology/ERA5_'+varstr+'_NH_daily_clim_'+str(year_range[0])+'-'+str(year_range[1])+'_sm'+str(n_window)+'d.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute anomalies from climatology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  ERA5_mslp_NH_daily_2024_anom.nc is saved\n"
     ]
    }
   ],
   "source": [
    "for file in sorted(all_files)[-1:]:\n",
    "    data = xr.open_dataset(file)\n",
    "    clim = xr.open_dataset(data_dir + 'climatology/ERA5_'+varstr+'_NH_daily_clim_'+str(year_range[0])+'-'+str(year_range[1])+'_sm'+str(n_window)+'d.nc')\n",
    "    clim = clim.sel(dayofyear=data['time'].dt.dayofyear).drop_vars(\"dayofyear\")\n",
    "    # clim = clim.rename({\"latitude\": \"lat\",\"longitude\": \"lon\"})\n",
    "    anom = data - clim\n",
    "    anom.to_netcdf(data_dir + file.split('/')[-1].split('.')[0] + '_anom.nc')\n",
    "    print('File ', file.split('/')[-1].split('.')[0] + '_anom.nc is saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env_xesmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
